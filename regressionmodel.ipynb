{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import re\n",
    "from pyper.chemometrics.dataset import HyperSpectralDataset\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torch.nn import Module\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import Linear\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Flatten\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as tfs\n",
    "import torch.cuda\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(DEVICE))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filepath</th>\n",
       "      <th>#seeds</th>\n",
       "      <th>batch</th>\n",
       "      <th>type</th>\n",
       "      <th>type seeds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E:\\dataset\\mixtures\\batch3\\FX10\\rogge2.h5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>mixtures</td>\n",
       "      <td>rogge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E:\\dataset\\mixtures\\batch3\\FX10\\rogge5.h5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>mixtures</td>\n",
       "      <td>rogge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E:\\dataset\\mixtures\\batch3\\FX10\\rogge8.h5</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>mixtures</td>\n",
       "      <td>rogge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E:\\dataset\\mixtures\\batch3\\FX10\\rogge10.h5</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>mixtures</td>\n",
       "      <td>rogge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E:\\dataset\\mixtures\\batch3\\FX10\\rogge13.h5</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>mixtures</td>\n",
       "      <td>rogge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>E:\\dataset\\pure\\batch12\\FX10\\haver8.h5</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>pure</td>\n",
       "      <td>haver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>E:\\dataset\\pure\\batch12\\FX10\\haver9.h5</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>pure</td>\n",
       "      <td>haver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>E:\\dataset\\pure\\batch12\\FX10\\haver10.h5</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>pure</td>\n",
       "      <td>haver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>E:\\dataset\\pure\\batch12\\FX10\\haver11.h5</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>pure</td>\n",
       "      <td>haver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>E:\\dataset\\pure\\batch12\\FX10\\haver12.h5</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>pure</td>\n",
       "      <td>haver</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Filepath  #seeds  batch      type  \\\n",
       "0     E:\\dataset\\mixtures\\batch3\\FX10\\rogge2.h5       2      3  mixtures   \n",
       "1     E:\\dataset\\mixtures\\batch3\\FX10\\rogge5.h5       5      3  mixtures   \n",
       "2     E:\\dataset\\mixtures\\batch3\\FX10\\rogge8.h5       8      3  mixtures   \n",
       "3    E:\\dataset\\mixtures\\batch3\\FX10\\rogge10.h5      10      3  mixtures   \n",
       "4    E:\\dataset\\mixtures\\batch3\\FX10\\rogge13.h5      13      3  mixtures   \n",
       "..                                          ...     ...    ...       ...   \n",
       "160      E:\\dataset\\pure\\batch12\\FX10\\haver8.h5       0     12      pure   \n",
       "161      E:\\dataset\\pure\\batch12\\FX10\\haver9.h5       0     12      pure   \n",
       "162     E:\\dataset\\pure\\batch12\\FX10\\haver10.h5       0     12      pure   \n",
       "163     E:\\dataset\\pure\\batch12\\FX10\\haver11.h5       0     12      pure   \n",
       "164     E:\\dataset\\pure\\batch12\\FX10\\haver12.h5       0     12      pure   \n",
       "\n",
       "    type seeds  \n",
       "0        rogge  \n",
       "1        rogge  \n",
       "2        rogge  \n",
       "3        rogge  \n",
       "4        rogge  \n",
       "..         ...  \n",
       "160      haver  \n",
       "161      haver  \n",
       "162      haver  \n",
       "163      haver  \n",
       "164      haver  \n",
       "\n",
       "[165 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataloader\n",
    "\n",
    "imagedir=Path('E:\\dataset')\n",
    "filepath=pd.Series(list(imagedir.glob(r'**/FX10/*.h5')), name='Filepath').astype(str)\n",
    "#determine the amount of seeds and seedtype\n",
    "seedsnbr= pd.Series(filepath.apply(lambda x: os.path.split(x)[1]), name='#seeds').astype(str)\n",
    "seedstype= pd.Series(filepath.apply(lambda x: os.path.split(x)[1]), name='type seeds').astype(str)\n",
    "seedsnbr=pd.Series(seedsnbr.apply(lambda x: x.replace(\".png\",\"\") )).astype(str)\n",
    "seedstype=pd.Series(seedstype.apply(lambda x: re.split('(\\d+)',x)[0] )).astype(str)\n",
    "seedsnbr=pd.Series(seedsnbr.apply(lambda x: re.split('(\\d+)',x)[1] )).astype(np.int32)\n",
    "# determine the batch number\n",
    "batchnbr=pd.Series(filepath.apply(lambda x: os.path.split(x)[0]), name='batch').astype(str)\n",
    "batchnbr=pd.Series(batchnbr.apply(lambda x: os.path.split(x)[0]), name='batch').astype(str)\n",
    "batchnbr_0=pd.Series(batchnbr.apply(lambda x: os.path.split(x)[1]), name='batch').astype(str)\n",
    "batchnbr_0=pd.Series(batchnbr_0.apply(lambda x: re.split('(\\d+)',x)[1] )).astype(np.int32)\n",
    "# determine if mixture or pure\n",
    "mixorpur=pd.Series(batchnbr.apply(lambda x: os.path.split(x)[0]), name='type').astype(str)\n",
    "mixorpur=pd.Series(mixorpur.apply(lambda x: os.path.split(x)[1]), name='type').astype(str)\n",
    "#makes sure that the amount of seeds is zero if dealing with pure sample\n",
    "seedsnbr[mixorpur=='pure']=0\n",
    "\n",
    "#make a list with all the data\n",
    "dataset_0=pd.concat([filepath,seedsnbr,batchnbr_0,mixorpur,seedstype],axis=1)\n",
    "dataset_0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath2='E:/dataset_numpy/'+batchnbr_0.astype(str)+'_'+(filepath.apply(lambda x: os.path.split(x)[1])).astype(str)\n",
    "filepath2=(filepath2.apply(lambda x: x.replace('h5','npy'))).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 500, 500])\n"
     ]
    }
   ],
   "source": [
    "#dataloader model (uses numpy array as input instead of .png)\n",
    "\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, target, img_dir, transform=None):\n",
    "        self.img_labels = target\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_dir[idx]\n",
    "        label=self.img_labels[idx]\n",
    "        image = np.load(img_path,allow_pickle=True)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "\n",
    "        return image,label\n",
    "\n",
    "class ToTensor(object):\n",
    "\n",
    "    def __call__(self, image):\n",
    "        image = image\n",
    "        # swap color axis because\n",
    "        # numpy image: Height x Width x Color\n",
    "        # torch image: Color x Height x Width\n",
    "        image = np.transpose(image,(2,0,1))\n",
    "        image=torch.from_numpy(image)\n",
    "\n",
    "        return image\n",
    "\n",
    "class Rescale(object):\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, image):\n",
    "        image=image\n",
    "\n",
    "        h, w = np.shape(image)[:2]\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "\n",
    "        image=np.float32(image)\n",
    "        image=cv2.resize(image,(new_h,new_h),interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "\n",
    "        # h and w are swapped for landmarks because for images,\n",
    "        # x and y axes are axis 1 and 0 respectively\n",
    "     \n",
    "\n",
    "        return image\n",
    "\n",
    "\n",
    "dim=np.shape(dataset_0)[0]\n",
    "train_size=np.floor(0.85*dim)\n",
    "test_size=dim-train_size\n",
    "dim_rand=np.random.permutation(np.arange(dim))\n",
    "idx_train=np.random.permutation(dim_rand[:int(train_size)])\n",
    "idx_test=np.random.permutation(dim_rand[int(train_size):])\n",
    "\n",
    "dataset_train=CustomImageDataset(img_dir=filepath2[idx_train],target=seedsnbr[idx_train],transform=tfs.Compose([Rescale(500),ToTensor()]))\n",
    "print(torch.Tensor.size(dataset_train[0][0]))\n",
    "dataset_test=CustomImageDataset(img_dir=filepath2[idx_test],target=seedsnbr[idx_test],transform=tfs.Compose([Rescale(500),ToTensor()]))\n",
    "dataloader_train=DataLoader(dataset_train,batch_size=16,shuffle=True)\n",
    "dataloader_test=DataLoader(dataset_test,batch_size=16,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "class Net(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv2d(3, 6, 5)\n",
    "        self.pool = MaxPool2d(2, 2)\n",
    "        self.conv2 = Conv2d(6, 16, 5)\n",
    "        self.fc1 = Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = Linear(120, 84)\n",
    "        self.fc3 = Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (16x238144 and 400x120)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\masterthesis\\code\\regression model\\regression model.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/masterthesis/code/regression%20model/regression%20model.ipynb#W6sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/masterthesis/code/regression%20model/regression%20model.ipynb#W6sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# forward + backward + optimize\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/masterthesis/code/regression%20model/regression%20model.ipynb#W6sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m outputs \u001b[39m=\u001b[39m net(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/masterthesis/code/regression%20model/regression%20model.ipynb#W6sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/masterthesis/code/regression%20model/regression%20model.ipynb#W6sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32md:\\masterthesis\\code\\regression model\\regression model.ipynb Cell 7\u001b[0m in \u001b[0;36mNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/masterthesis/code/regression%20model/regression%20model.ipynb#W6sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool(F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x)))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/masterthesis/code/regression%20model/regression%20model.ipynb#W6sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mflatten(x, \u001b[39m1\u001b[39m) \u001b[39m# flatten all dimensions except batch\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/masterthesis/code/regression%20model/regression%20model.ipynb#W6sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc1(x))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/masterthesis/code/regression%20model/regression%20model.ipynb#W6sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc2(x))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/masterthesis/code/regression%20model/regression%20model.ipynb#W6sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc3(x)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (16x238144 and 400x120)"
     ]
    }
   ],
   "source": [
    "#train model\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i,sample in enumerate(dataloader_train):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        input,labels=sample\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(input)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {sample + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "650fa92be31bf650066ac4047dcada211305a7063c331efd6a8c08465b54e9de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
